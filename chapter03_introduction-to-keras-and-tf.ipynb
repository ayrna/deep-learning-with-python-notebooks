{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yX7I6IkPe-N"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayrna/deep-learning-with-python-notebooks/blob/master/chapter03_introduction-to-keras-and-tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLlJ5DqIKTIS"
      },
      "source": [
        "\n",
        "**EJERCICIOS**: Durante este cuaderno de pr谩cticas ver谩s ejercicios y preguntas marcadas con  **EJERCICIO** que adem谩s aparecen en el 铆ndice de navegaci贸n. Puedes contestar a帽adiendo nuevos bloques de texto (breve) y/o c贸digo a continuaci贸n de la pregunta.\n",
        "\n",
        "**NOTA**: La IA generativa puede resolver la mayor铆a de los ejercicios porque son muy f谩ciles. Precisamente son f谩ciles para hacer una toma de contacto desde abajo y entender todas las piezas as铆 que deber铆an resolverse sin IA por aquello del \"Learning by doing\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cuaderno est谩 basado en los cuadernos del libro [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) y [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition).\n",
        "\n",
        "> This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        ">\n",
        "> **If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        ">\n",
        "> The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io).\n"
      ],
      "metadata": {
        "id": "8g4pfqghaPeD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzy5cZNbKTIX"
      },
      "source": [
        "# Introducci贸n a Keras y TensorFlow, PyTorch y JAX\n",
        "\n",
        "Keras es un framework con un API de alto nivel de apstracci贸n para desarrollar y desplegar modelos de aprendizaje profundo. Se usa ampliamente en la industria e investigaci贸n y es de los m谩s populares en comunidades como Kaggle.\n",
        "\n",
        "Keras se puede utilizar junto con JAX, TensorFlow o PyTorch. Son los \"marcos de trabajo de *backend*\" de Keras. A trav茅s de estos *backend*, Keras puede ejecutarse en diferentes tipos de hardware (GPU, TPU o CPU), se puede escalar sin problemas a miles de m谩quinas y se puede implementar en una variedad de plataformas. Todo el c贸digo escrito con el API de Keras puede ejecutarse en los 3 entornos si bien debe importarse keras despu茅s de elegirlo. El backend por defecto es TensorFlow.\n",
        "\n",
        "* TensorFlow (https://tensorflow.org).\n",
        "* PyTorch (https://pytorch.org/).\n",
        "* JAX (https://jax.readthedocs.io/).\n",
        "\n",
        "Si bien en DL tenemos un contexto multi-framework el lenguaje claramente ganador es Python, aunque existan APIs para muchos otros populares en ciencia de datos.\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "# Sets the environment variable from within the Python runtime\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "# Only then should you import Keras.\n",
        "import keras\n",
        "```\n",
        "\n",
        "![imagen.png](attachment:0c443ed4-3f29-43a8-b435-cede57f38866.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V96G_3z1AHGp"
      },
      "source": [
        "La 煤ltima versi贸n estable de Keras es la versi贸n 3.0, que incluye estos tres backends y adem谩s NumPy con algunas limitaciones.\n",
        "\n",
        "https://keras.io/\n",
        "\n",
        "Puede interesarte mirar la galer铆a de ejemplos:\n",
        "\n",
        "https://keras.io/examples/\n",
        "\n",
        "Y Keras Hub, que es la colecci贸n de modelos pre-entrenados:\n",
        "\n",
        "https://keras.io/keras_hub/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBFz-vNwOrwe"
      },
      "source": [
        "## 驴C贸mo se relacionan estas herramientas?\n",
        "\n",
        "Entrenar redes neuronales gira en torno a varios conceptos:\n",
        "\n",
        "1. La manipulaci贸n de tensores a **bajo nivel**, la *infraestructura* que subyace a todo el aprendizaje autom谩tico moderno. Esto se traduce en las APIs de **TensorFlow**, **PyTorch** o **JAX**:\n",
        " * *Tensores*, incluyendo tensores especiales que almacenan el estado de la red (variables)\n",
        " * *Operaciones de tensor* como la `suma`, `relu`, `matmul`\n",
        " * *Retropropagaci贸n (Backpropagation)*, una forma de calcular el gradiente de expresiones matem谩ticas (e.j. en TensorFlow a trav茅s del objeto `GradientTape`)\n",
        "2. Conceptos de aprendizaje profundo de **alto nivel**. Esto se traduce en las APIs de **Keras**:\n",
        " * *Capas*, que se combinan en un modelo\n",
        " * *Funci贸n de p茅rdida*, que define la se帽al de retroalimentaci贸n utilizada para el aprendizaje\n",
        " * *Optimizador*, que determina c贸mo se realiza el ajuste/aprendizaje a los datos.\n",
        " * *M茅tricas* para evaluar el rendimiento del modelo, como la precisi贸n\n",
        " * Un *bucle de entrenamiento* que realiza el descenso de gradiente estoc谩stico en mini lotes\n",
        "\n",
        "Aqu铆 vamos ver los ejemplos b谩sicos con TensorFlow. Tienes el c贸digo equivalente para PyTorch y JAX en <https://deeplearningwithpython.io/chapters/chapter03_introduction-to-ml-frameworks/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKyiVRJBKTIn"
      },
      "source": [
        "## Primeros pasos con TensorFlow\n",
        "\n",
        "TensorFlow es un marco de aprendizaje autom谩tico de c贸digo abierto basado en Python desarrollado principalmente por Google. Adem谩s de esto es una plataforma donde hay multitud de componentes, entre ellos muchos que facilitan el despliegue, y es por esto que se utiliza mucho en la industria.\n",
        "\n",
        "Los conceptos clave que vamos a ver son:\n",
        " * Tensores y variables.\n",
        " * Operaciones num茅ricas en TF.\n",
        " * Calcular gradientes con `GradientTape`.\n",
        " * Hacer m谩s eficiente la ejecuci贸n de funciones (just-in-time compilation).\n",
        "\n",
        "NOTA. Si has instalado TF en local quiz谩s te aparece este mensaje sobre los registros para operaciones con vectores:\n",
        "\n",
        "```\n",
        "This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
        "```\n",
        "\n",
        "Puedes recompilar TF o deshabilitar estos mensajes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NOOVY9IOrwf"
      },
      "outputs": [],
      "source": [
        "# Para eliminar los mensajes sobre registros del procesador\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYFtk25gKTIo"
      },
      "source": [
        "#### Tensores constantes y variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVD4LEMgOPRC"
      },
      "source": [
        "El tensor es la estructura de datos b谩sica de TensorFlow y Keras. Deben crearse con un contenido y no se les puede asignar un valor.\n",
        "\n",
        "Cuando es necesario cambiar el estado de una variable necesitaremos el tipo `tf.Variable`, que deben crearse con un valor inicial tambi茅n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjdQ6GXzKTIo"
      },
      "source": [
        "**Tensores constantes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DhYi-8CKTIp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# Equivalent to np.ones(shape=(2, 1))\n",
        "x = tf.ones(shape=(2, 1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43DzLxyvKTIr"
      },
      "outputs": [],
      "source": [
        "# Equivalent to np.zeros(shape=(2, 1))\n",
        "x = tf.zeros(shape=(2, 1))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW2oxna4Orwi"
      },
      "outputs": [],
      "source": [
        "# Equivalent to np.array([1, 2, 3], dtype=\"float32\")\n",
        "tf.constant([1, 2, 3], dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSA4b6GHKTIr"
      },
      "source": [
        "**Tensores aleatorios**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEmRkf-HKTIr"
      },
      "outputs": [],
      "source": [
        "# np.random.normal(size=(3, 1), loc=0., scale=1.).\n",
        "x = tf.random.normal(shape=(3, 1), mean=0., stddev=1.)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05CGedl5KTIs"
      },
      "outputs": [],
      "source": [
        "# np.random.uniform(size=(3, 1), low=0., high=1.).\n",
        "x = tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhiR3zqfKTIt"
      },
      "source": [
        "**Los arrays de NumPy son asignables pero los tensores no**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdnfCFsUKTIt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "x = np.ones(shape=(2, 2))\n",
        "x[0, 0] = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMELAOHUO9WI"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  x = tf.ones(shape=(2, 2))\n",
        "  x[0, 0] = 0.\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNU6758FKTIt"
      },
      "source": [
        "**Crear un TensorFlow variable**\n",
        "\n",
        "Para entrenar un modelo tenemos que modificar tensores, y para esto se usa el tipo `tf.Variable` que debe crearse siempre con un valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5Uubtf1KTIu"
      },
      "outputs": [],
      "source": [
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3, 1)))\n",
        "print(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgiNms9hKTIv"
      },
      "source": [
        "**Asignar un valor a un TensorFlow variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8pAzAXbKTIv"
      },
      "outputs": [],
      "source": [
        "v.assign(tf.ones((3, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1iz3U4bKTIw"
      },
      "source": [
        "**Asignar un valor a un subconjunto de un TensorFlow variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85C5QwR-KTIw"
      },
      "outputs": [],
      "source": [
        "v[0, 0].assign(3.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDjhxQ-aKTIw"
      },
      "source": [
        "**Suma con `assign_add`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eStLXrkJKTIx"
      },
      "outputs": [],
      "source": [
        "v.assign_add(tf.ones((3, 1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bFwaV0LKTIy"
      },
      "source": [
        "#### Operaciones matem谩ticas con Tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ0pHWDxKTIy"
      },
      "source": [
        "**Operaciones b谩sicas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvFbtDZTKTIy"
      },
      "outputs": [],
      "source": [
        "a = tf.ones((2, 2))\n",
        "b = tf.square(a)\n",
        "c = tf.sqrt(a)\n",
        "d = b + c\n",
        "e = tf.matmul(a, b)\n",
        "e *= d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0ISrkpSKTIy"
      },
      "source": [
        "#### GradientTape API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vRfqlJQKTIy"
      },
      "source": [
        "**C贸mo usar `GradientTape`**\n",
        "\n",
        "Basta con abrir un *谩mbito* de `GradientTape`, aplicar alg煤n c谩lculo(s) a uno o varios tensores de entrada, y recuperar el gradiente del resultado con respecto a las entradas.\n",
        "\n",
        "$f(x)=x^2$\n",
        "\n",
        "$\n",
        "\\frac{\\partial f}{\\partial x} = 2x\n",
        "$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u852m1xKTI0"
      },
      "outputs": [],
      "source": [
        "input_var = tf.Variable(initial_value=3.)\n",
        "with tf.GradientTape() as tape:\n",
        "   result = tf.square(input_var)\n",
        "gradient = tape.gradient(result, input_var)\n",
        "# la funci贸n ser铆a f(x)=x^2; f'(x)=2x, siendo x = 3 f'(x)=6\n",
        "print(input_var)\n",
        "print(gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmgIjR9aKTI0"
      },
      "source": [
        "**`GradientTape` con tensores constantes como entrada**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRcTyxsiRvFN"
      },
      "source": [
        "Hasta ahora, s贸lo hemos visto el caso en que los tensores de entrada en `tape.gradient()` eran variables TensorFlow. En realidad es posible que estas entradas sean cualquier tensor arbitrario. Sin embargo, s贸lo las variables entrenables son *rastreadas* por defecto. Con un tensor constante, hay que marcarlo manualmente como rastreado llamando a `tape.watch()` sobre 茅l. Esto se hace por motivos de eficiencia computacional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTvvjZbKKTI1"
      },
      "outputs": [],
      "source": [
        "input_const = tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "   tape.watch(input_const)\n",
        "   result = tf.square(input_const)\n",
        "gradient = tape.gradient(result, input_const)\n",
        "print(result)\n",
        "print(gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv52-TtaOrwo"
      },
      "source": [
        "### Acelerar las funciones de TensorFlow mediante la compilaci贸n\n",
        "\n",
        "Todo el c贸digo que hemos ejecutado hasta ahora se ha ejecutado de forma interpretada y secuencialmente (a veces le llaman ejecuci贸n \"ansiosa\" o \"eagerly\"). El concepto de compilaci贸n a grandes rasgos consiste en reescribir el c贸digo Python de forma m谩s r谩pida y eficiente para aprovechar paralelismos, reducir pasos de datos, etc. Puedes mirar algunos resultados de esta optimizaci贸n ([aqu铆](https://dev.to/dev_tips/pytorch-vs-tensorflow-2025-which-one-wins-after-72-hours-a2b) y [aqu铆](https://blog.tensorflow.org/2018/11/pushing-limits-of-gpu-performance-with-xla.html))\n",
        "\n",
        "Estas optimizaciones dificultan-imposibilitan la depuraci贸n de manera que la activaremos una vez hemos depurado nuestro c贸digo.\n",
        "\n",
        "Puedes aplicar la compilaci贸n a cualquier funci贸n de TensorFlow envolvi茅ndola en un decorador `tf.function`, de la siguiente manera:\n",
        "\n",
        "```python\n",
        "# @tf.function(jit_compile=True) activar铆a la compilaci贸n con el compilador XLA de alto rendimiento\n",
        "@tf.function\n",
        "def dense(inputs, W, b):\n",
        "    return tf.nn.relu(tf.matmul(inputs, W) + b)\n",
        "```\n",
        "\n",
        "En el paso `compile` que veremos m谩s adelante tambi茅n [se puede parametrizar esta optimizaci贸n](https://keras.io/2/api/models/model_training_apis/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "redCwR3sOrwo"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de la documentaci贸n de TF https://www.tensorflow.org/guide/function?hl=es-419\n",
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
        "\n",
        "@tf.function\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1, 200, 200, 100])\n",
        "# Warm up\n",
        "conv_layer(image); conv_fn(image)\n",
        "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
        "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
        "print(\"Note how there's not much difference in performance for convolutions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqKfGzf2Orwo"
      },
      "outputs": [],
      "source": [
        "# Ejemplo de la documentaci贸n de TF https://www.tensorflow.org/guide/function?hl=es-419\n",
        "import timeit\n",
        "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def conv_fn(image):\n",
        "  return conv_layer(image)\n",
        "\n",
        "image = tf.zeros([1, 200, 200, 100])\n",
        "# Warm up\n",
        "conv_layer(image); conv_fn(image)\n",
        "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
        "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
        "print(\"Note how there's not much difference in performance for convolutions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQH2QkHjKTI2"
      },
      "source": [
        "#### Un clasificador lineal completo en TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_CaD-nmKTI2"
      },
      "source": [
        "**Generaci贸n del conjunto de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaRLZE7MKTI2"
      },
      "outputs": [],
      "source": [
        "num_samples_per_class = 1000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1wa_98KKTI3"
      },
      "outputs": [],
      "source": [
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbNx-pwBKTI3"
      },
      "outputs": [],
      "source": [
        "targets = np.vstack(\n",
        "    (\n",
        "        np.zeros((num_samples_per_class, 1), dtype=\"float32\"),\n",
        "        np.ones((num_samples_per_class, 1), dtype=\"float32\")\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZTuA8VWKTI4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-hKLGpdKTI4"
      },
      "source": [
        "**Creaci贸n de la variables del modelo lineal**\n",
        "\n",
        "Inicializamos `W` con valores aleatorios y `b` a cero.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqadhSZTKTI4"
      },
      "outputs": [],
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tj-9u9wKTI6"
      },
      "source": [
        "**Propagaci贸n hacia delante**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntvoFKavKTI6"
      },
      "outputs": [],
      "source": [
        "def model(inputs):\n",
        "    return tf.matmul(inputs, W) + b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-_dDjgJKTI6"
      },
      "source": [
        "**Funci贸n de p茅rdia de error cuadr谩tico medio (MSE)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWOFtzq9iuld"
      },
      "source": [
        "* `persample_loss` es un tensor con la misma forma que targets y predictions y almacenar谩 la p茅rdida correspondiente a cada patr贸n.\n",
        "* Devolvemos la contribuci贸n media al error del lote. `reduce_mean` por defecto reduce todas las dimensiones a 1, pero podr铆a utilizarse para calcular medias por ejes del tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9gDDk0eKTI6"
      },
      "outputs": [],
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)\n",
        "    # media de la p茅rdida por patr贸n\n",
        "    return tf.reduce_mean(per_sample_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NQxVCqKTI7"
      },
      "source": [
        "**El paso de entrenamiento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0-GJqnlhAR3"
      },
      "source": [
        "Recordad que `GradientTape` nos permite derivar respecto a listas de par谩metros. En este caso nos devuelve el gradiente parcial respecto a cada par谩metro de la lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YfXjhpkKTI7"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "@tf.function(jit_compile=True)\n",
        "def training_step(inputs, targets):\n",
        "    # Forward pass dentro del GradientTape\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = square_loss(targets, predictions)\n",
        "    # Gradiente respecto a los pesos\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
        "    # Actualizamos los pesos restando el gradiente (direcci贸n contraria w = w - lr*grad)\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate)\n",
        "    b.assign_sub(grad_loss_wrt_b * learning_rate)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBoJ6K_vKTI8"
      },
      "source": [
        "**Bucle de aprendizaje con el conjunto completo (batch training)**\n",
        "\n",
        "Para simplificar, haremos un entrenamiento por lotes en lugar de un mini-entrenamiento por lotes: ejecutaremos cada paso de entrenamiento (c谩lculo del gradiente y actualizaci贸n de pesos) para todos los datos, en lugar de iterar sobre los datos en peque帽os lotes.\n",
        "\n",
        "Esto significa que cada paso de entrenamiento tardar谩 mucho m谩s tiempo en ejecutarse pero cada actualizaci贸n del gradiente ser谩 mucho m谩s eficaz para reducir la funci贸n de p茅rdida al incluir todos los datos de entrenamiento. Esto significa que har谩n falta menos pasos de entrenamiento y que la tasa de aprendizaje deber铆a ser mayor que al utilizar lotes peque帽os (`learning_rate = 0.1`).\n",
        "\n",
        "####  **EJERCICIO**\n",
        "* Prueba a utilizar distintas tasas de aprendizaje en este ejemplo y observa el resultado\n",
        "* 驴[Tiene sentido que la tasa de aprendizaje sea mayor que 1](https://ai.stackexchange.com/questions/23740/why-is-the-learning-rate-generally-beneath-1)?\n",
        "* Intenta programar otra funci贸n de p茅rdida: el RMSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "6emud_9aOrwu"
      },
      "source": [
        "Pincha aqu铆 despu茅s de experimentar con la tasa de aprendizaje.\n",
        "\n",
        "<img src=\"https://github.com/ayrna/deep-learning-with-python-notebooks/blob/master/media/chapter03_introduction-to-keras-and-tf_convergencia_learning_rates.png?raw=1\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5y2nK1KKTI8"
      },
      "outputs": [],
      "source": [
        "for step in range(40):\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"Loss at step {step}: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJjDn_v6p0b0"
      },
      "source": [
        "Como vemos la funci贸n de p茅rdida m谩s o menos se estabiliza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg7GJbDIOrwu"
      },
      "source": [
        "Ahora vamos a predecir la clase de los patrones. En este ejemplo de clasificaci贸n binaria el umbral de decisi贸n entre las clases es `0.5` donde se asigna la clase \"1\" para los valores mayores que el umbral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLuywB26KTI8"
      },
      "outputs": [],
      "source": [
        "predictions = model(inputs)\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjvzPWm2KTI9"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 4, 100)\n",
        "y = - W[0] /  W[1] * x + (0.5 - b) / W[1]\n",
        "plt.plot(x, y, \"-r\")\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsbXu-6hKTI9"
      },
      "source": [
        "## Anatom铆a de una red neuronal para entender conceptos de Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atUcKC3MKTI-"
      },
      "source": [
        "### Capas (Layers)\n",
        "\n",
        "La estructura de datos fundamental en las redes neuronales es la *capa*. Una capa es un m贸dulo de procesamiento de datos que toma como entrada uno o m谩s tensores y que da como salida uno o m谩s tensores. Algunas capas no tienen estado, pero lo m谩s frecuente es que las capas tengan un estado: los *pesos* de la capa, uno o varios tensores aprendidos con el descenso por gradiente, que en conjunto almacenan el *conocimiento* de la red.\n",
        "\n",
        "Seg煤n el tipo de dato con el que trabajemos habr谩 tipos de capas m谩s apropiados para trabajar con estos.\n",
        "* Datos vectoriales simples, tambi茅n llamados tabulares (\"hoja de c谩lculo\"), almacenados en tensores de rango 2 `(muestra, caracter铆sticas)`, suelen ser procesados por capas densamente conectadas, tambi茅n llamadas capas totalmente conectadas (la clase `Dense` en Keras).\n",
        "* Los datos con disposici贸n temporal o de secuencia, tensores de rango 3 `(muestras, pasos de tiempo, caracter铆sticas)`, se procesan normalmente por capas recurrentes, como una capa `LSTM`, o capas de convoluci贸n 1D (`Conv1D`).\n",
        "* Los datos de im谩genes, almacenados en tensores de rango 4, suelen ser procesados por capas de convoluci贸n 2D (`Conv2D`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D21FZwD4KTI-"
      },
      "source": [
        "#### La clase `Layer` en Keras\n",
        "\n",
        "\n",
        "Casi todo en Keras gira en torno a un objeto de tipo Layer, que encapsula un estado de los pesos y un c谩lculo sobre la red (*forward pass*). Los pesos se definen en `build()` y el procesamiento en `call()`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgMFet7GKTI-"
      },
      "source": [
        "**Una capa `Dense` implementada como subclase de `Layer`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKFXB9GSKTI-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "class SimpleDense(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, activation=None):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim = input_shape[-1]\n",
        "        self.W = self.add_weight(shape=(input_dim, self.units),\n",
        "                                 initializer=\"random_normal\")\n",
        "        self.b = self.add_weight(shape=(self.units,),\n",
        "                                 initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y = tf.matmul(inputs, self.W) + self.b\n",
        "        if self.activation is not None:\n",
        "            y = self.activation(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lp8AkEyu02i"
      },
      "source": [
        "Esta capa que hemos creado se puede instanciar y usarse como una funci贸n:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZmz_BQRKTI_"
      },
      "outputs": [],
      "source": [
        "my_dense = SimpleDense(units=32, activation=tf.nn.relu)\n",
        "input_tensor = tf.ones(shape=(2, 784))\n",
        "output_tensor = my_dense(input_tensor)\n",
        "print(output_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-3t_thIu-1s"
      },
      "outputs": [],
      "source": [
        "my_dense = SimpleDense(units=512, activation=tf.nn.tanh)\n",
        "input_tensor = tf.ones(shape=(2, 784))\n",
        "output_tensor = my_dense(input_tensor)\n",
        "print(output_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYqRul6oKTI_"
      },
      "source": [
        "#### Deducci贸n de la forma de la capa autom谩tica: construcci贸n de capas sobre la marcha"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r32G-GMvemc"
      },
      "source": [
        "En Keras en general s贸lo necesitaremos especificar la forma de los tensores de salida de la capa, ya que las capas que se a帽aden al modelo se construyen din谩micamente para adaptar cada capa a la forma de la capa de entrada (la salida de la capa anterior)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeaWJ7kvv9vM"
      },
      "source": [
        "La siguiente capa s贸lo puede conectarse a una capa que espere vectores de 32 dimensiones como entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG87ONtCKTI_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "layer = layers.Dense(32, activation=\"relu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q31sRXyVwE-_"
      },
      "source": [
        "En Keras, no se implementa la construcci贸n de la capa del todo en el constructor `__build__()` en espera de conocer cu谩l ser谩 la forma de la entrada desde la capa anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0iPGmzDKTI_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "model = models.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(32)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6YKkaxtwcQx"
      },
      "source": [
        "En el ejemplo de red que hicimos desde cero necesit谩bamos especificar perfectamente las dimensiones de entrada y salida de la secuencia de capas:\n",
        "\n",
        "```\n",
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=784, output_size=32, activation=\"relu\"),\n",
        "    NaiveDense(input_size=32, output_size=64, activation=\"relu\"),\n",
        "    NaiveDense(input_size=64, output_size=32, activation=\"relu\"),\n",
        "    NaiveDense(input_size=32, output_size=10, activation=\"softmax\")\n",
        "])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOwolWkWwnoI"
      },
      "source": [
        "En Keras basta con lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZgfKF5pKTJA"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    SimpleDense(32, activation=\"relu\"),\n",
        "    SimpleDense(64, activation=\"relu\"),\n",
        "    SimpleDense(32, activation=\"relu\"),\n",
        "    SimpleDense(1, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqGUwElFKTJA"
      },
      "source": [
        "### De las capas a los modelos\n",
        "\n",
        "Un modelo de aprendizaje profundo consiste en un grafo de capas, clase `Model` en Keras. Hasta ahora s贸lo hemos visto el modelo `Sequential`, que es una subclase de `Model` pero existen muchas otras topolog铆as de red m谩s avanzadas (Transformers, [`Residual`](https://keras.io/api/applications/resnet/)...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfY2dELVKTJA"
      },
      "source": [
        "### El paso \"compile\" para configurar el proceso de aprendizaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD_WVkPnxwC4"
      },
      "source": [
        "Aqu铆 vamos a configurar:\n",
        "* Funci贸n de p茅rdida (o funci贸n objetivo).\n",
        "* El optimizador.\n",
        "* M茅tricas de evaluaci贸n sobre el conjunto de train y opcionalmente validaci贸n.\n",
        "\n",
        "Hay dos alternativas para especificar esto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--uxOt36KTJB"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1)])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"mean_squared_error\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UONW9yKKTJB"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFumPtBWKTJB"
      },
      "source": [
        "### La importancia de la funci贸n de p茅rdida \n",
        "\n",
        "La elecci贸n de la funci贸n de p茅rdida correcta para el problema adecuado es extremadamente importante: la red tomar谩 cualquier atajo que pueda para minimizar la p茅rdida, por lo que si el objetivo no est谩 totalmente correlacionado con la tarea en cuesti贸n, la red terminar谩 haciendo cosas que probablemente no queramos.\n",
        "\n",
        "Ejemplos:\n",
        "* 驴detector de emociones?\n",
        "* 驴maximizar el bienestar promedio de los seres humanos?\n",
        "* [Hundreds of AI tools have been built to catch covid. None of them helped.](https://www.technologyreview.com/2021/07/30/1030329/machine-learning-ai-failed-covid-hospital-diagnosis-pandemic/)\n",
        "* [Leakage and the reproducibility crisis in machine-learning-based science](https://www.sciencedirect.com/science/article/pii/S2666389923001599)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNE9EC25KTJC"
      },
      "source": [
        "### El m茅todo fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa6z8y8lKTJC"
      },
      "source": [
        "**Calling `fit()` with NumPy data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AQi7fsRKTJC"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    inputs,\n",
        "    targets,\n",
        "    epochs=5,\n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQKA8RTNKTJD"
      },
      "outputs": [],
      "source": [
        "history.history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWOpQ7csKTJD"
      },
      "source": [
        "### Monitorizaci贸n de la p茅rdida y las m茅tricas sobre datos de validaci贸n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXJb3QNdKTJD"
      },
      "source": [
        "**Par谩metro `validation_data`**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEn2yZFyKTJD"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([keras.layers.Dense(1)])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.1),\n",
        "              loss=keras.losses.MeanSquaredError(),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "indices_permutation = np.random.permutation(len(inputs))\n",
        "shuffled_inputs = inputs[indices_permutation]\n",
        "shuffled_targets = targets[indices_permutation]\n",
        "\n",
        "num_validation_samples = int(0.3 * len(inputs))\n",
        "val_inputs = shuffled_inputs[:num_validation_samples]\n",
        "val_targets = shuffled_targets[:num_validation_samples]\n",
        "training_inputs = shuffled_inputs[num_validation_samples:]\n",
        "training_targets = shuffled_targets[num_validation_samples:]\n",
        "model.fit(\n",
        "    training_inputs,\n",
        "    training_targets,\n",
        "    epochs=5,\n",
        "    batch_size=16,\n",
        "    validation_data=(val_inputs, val_targets)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmVx8Z-qKTJE"
      },
      "source": [
        "### C贸mo usar el modelo entrenado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jffLo6HvzF4S"
      },
      "source": [
        "Se puede llamar al modelo como una funci贸n, pero esto evaluar铆a toda la base de datos de test directamente en lugar de por lotes.\n",
        "\n",
        "```\n",
        "predictions = model(new_inputs)\n",
        "```\n",
        "\n",
        "Habitualmente ser谩 m谩s adecuado usar la funci贸n `predict`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__d2SikiKTJE"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(val_inputs, batch_size=128)\n",
        "print(predictions[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIK1RSHxzi7X"
      },
      "source": [
        "####  **EJERCICIO**\n",
        "\n",
        "* Prueba a utilizar el modelo anterior de 4 capas con la base de datos MNIST\n",
        "  * No bastar谩 con copiar y pegar. Presta atenci贸n a: variables de entrada, funci贸n de p茅rdida adecuada, neuronas por capa... Deber谩s calcular la precisi贸n media en test.\n",
        "* Prueba a visualizar el historial de ajuste del modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxhnOcIqftgz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4-ZgRhDhSEB"
      },
      "outputs": [],
      "source": [
        "# Puedes usar este c贸digo para visualizar el hist贸rico de entrenamiento\n",
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "acc_values = history_dict[\"accuracy\"]\n",
        "plt.plot(loss_values, \"b-\", label=\"Training loss\")\n",
        "plt.plot(acc_values, \"bo\", label=\"Training accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORm4K2LMDmzF"
      },
      "source": [
        "####  **EJERCICIO**\n",
        "\n",
        "Prueba a usar el ejemplo de red neuronal convolucional disponible [aqu铆](https://keras.io/examples/vision/mnist_convnet/) y a realizar una evaluaci贸n similar. Explica qu茅 observas en t茅rminos de rendimiento de clasificaci贸n y tiempo de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAwGptX2DzlZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT_q7bpOKTJE"
      },
      "source": [
        "## Resumen\n",
        "* TensorFlow es un *framework* que puede ejecutarse en CPU, GPU y TPU.\n",
        "* TensorFlow puede calcular el gradiente de cualquier expresi贸n diferenciable.\n",
        "* Keras es un API para hacer modelos de aprendizaje profundo con TF.\n",
        "* Objetos claves de TF: tensores, variables, operaciones con tensores y *GradientTape*.\n",
        "* La clase central de Keras es `Layer`, que encapsula algunos pesos y c谩lculos. Las capas se unen o ensamblan en **modelos**.\n",
        "* Antes de entrenar un modelo es necesario elegir un **optimizador**, una **funci贸n de p茅rdida** y una o varias **m茅tricas**: `model.compile()`\n",
        "* El m茅todo `model.fit()` ejecuta el descenso por gradiente por mini-lotes. Permite monitorizar la p茅rdida y m茅tricas y incluir datos de **validaci贸n**.\n",
        "* Con el modelo entrenado, se pueden hacer predicciones con `model.predict()`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter03_introduction-to-keras-and-tf.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}