{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayrna/deep-learning-with-python-notebooks/blob/master/chapter02_network-from-scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leKwkJPWvPV3"
      },
      "source": [
        "# Los bloques de construcci贸n matem谩ticos del aprendizaje profundo (parte II)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLKqo45Tu80M"
      },
      "source": [
        "En este cuaderno vamos a ver:\n",
        "\n",
        "* Un ejemplo de red neuronal\n",
        "* El concepto de tensor y operaciones con tensores\n",
        "* C贸mo las redes neuronales aprenden a trav茅s del algoritmo de retropropagaci贸n y el descenso por gradiente\n",
        "\n",
        "**EJERCICIOS**: Durante este cuaderno de pr谩cticas ver谩s ejercicios y preguntas marcadas con  **EJERCICIO** que adem谩s aparecen en el 铆ndice de navegaci贸n. Puedes contestar a帽adiendo nuevos bloques de texto (breve) y/o c贸digo a continuaci贸n de la pregunta.\n",
        "\n",
        "**NOTA**: La IA generativa puede resolver la mayor铆a de los ejercicios porque son muy f谩ciles. Precisamente son f谩ciles para hacer una toma de contacto desde abajo y entender todas las piezas as铆 que deber铆an resolverse sin IA por aquello del \"Learning by doing\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I35kAPLu7Z0"
      },
      "source": [
        "Este cuaderno est谩 basado en los cuadernos del libro [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) y [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition).\n",
        "\n",
        "> This is a companion notebook for the book [Deep Learning with Python, Third Edition](https://www.manning.com/books/deep-learning-with-python-third-edition). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        ">\n",
        "> **If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        ">\n",
        "> The book's contents are available online at [deeplearningwithpython.io](https://deeplearningwithpython.io)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # \"torch\" o \"jax\" disponibles"
      ],
      "metadata": {
        "id": "OxATWsN3JcGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def backend(line, cell):\n",
        "    current, required = os.environ.get(\"KERAS_BACKEND\", \"\"), line.split()[-1]\n",
        "    if current == required:\n",
        "        get_ipython().run_cell(cell)\n",
        "    else:\n",
        "        print(\n",
        "            f\"This cell requires the {required} backend. To run it, change KERAS_BACKEND to \"\n",
        "            f\"\\\"{required}\\\" at the top of the notebook, restart the runtime, and rerun the notebook.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "FZaAR6cMJeC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPUYr1xugWP"
      },
      "source": [
        "### Reimplementando nuestro ejemplo desde cero en TensorFlow\n",
        "\n",
        "Una forma de poner a prueba lo que se ha aprendido sobre algo es implementarlo \"desde cero\". Y esto vamos a hacer con una red neuronal. Obviamente no vamos a reimplementar operadores de matrices o algoritmos de optimizaci贸n, pero si los componentes b谩sicos de una red.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rad4u8KugWP"
      },
      "source": [
        "#### Clase Dense\n",
        "\n",
        "La clase `Dense` implementa la siguiente transformaci贸n de los datos de entrada donde `W` y `b` son los datos del modelo:\n",
        "\n",
        "```\n",
        "output = activation(dot(W, input) + b)\n",
        "```\n",
        "\n",
        "Donde la funci贸n de actividad suele ser `relu` para capas ocultas o `softmax` en la 煤ltima capa.\n",
        "\n",
        "**Nota de orientaci贸n a objetos en Python**:\n",
        "* El m茅todo `__init__` es el constructor de la clase y se llama al crear una instancia de la clase para asignar valores por defecto a los atributos de la clase.\n",
        "* El m茅todo `__call__` es el m茅todo que se lanza cuando se llama a la instancia de la clase como si fuera una funci贸n.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGqA3sy3ugWP"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "# keras.ops is where you will find all the tensor operations you need.\n",
        "from keras import ops\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation=None):\n",
        "        self.activation = activation\n",
        "        # Creamos una matriz inicializada aleatoriamente de forma (input_size, output_size)\n",
        "        self.W = keras.Variable(\n",
        "            shape=(input_size, output_size), initializer=\"uniform\"\n",
        "        )\n",
        "        # Vector inicializado con ceros de forma (output_size,)\n",
        "        self.b = keras.Variable(shape=(output_size,), initializer=\"zeros\")\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = ops.matmul(inputs, self.W)\n",
        "        x = x + self.b\n",
        "        if self.activation is not None:\n",
        "            x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IryasMQKuuhz"
      },
      "source": [
        "**Nota de orientaci贸n a objetos en Python**: `@property` se utiliza para definir un m茅todo `weights` que se comporta como un atributo/propiedad lo que significa que puede ser accedido como objeto sin la necesidad de llamarlo como un m茅todo (`objeto.weights()`). La funci贸n weights devuelve una lista que contiene los pesos (W) y los sesgos (b) de la capa. Esto permite que sean accesibles desde fuera de la clase pero al mismo tiempo que no se puedan modificar directamente fuera de la clase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsE9tTRssFKp"
      },
      "source": [
        "####  **EJERCICIO** no entregable: Intenta cambiar la forma de inicializaci贸n de los pesos y observa el efecto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX0Aiyr3ugWQ"
      },
      "source": [
        "#### Clase Sequential\n",
        "\n",
        "Esta clase se va a encargar de encadenar las capas. Va a empaquetar una lista de capas y expone un m茅todo `__call__()` que simplemente llama en orden a las capas subyacentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfso4YniugWQ"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        weights = []\n",
        "        for layer in self.layers:\n",
        "            weights += layer.weights\n",
        "        return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j81P9OhoQetU"
      },
      "source": [
        "Usando las clases `NaiveDense` y `NaiveSequential` podemos crear algo similar a un modelo de Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOIdPFPbugWQ"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential(\n",
        "    [\n",
        "        NaiveDense(input_size=28 * 28, output_size=512, activation=ops.relu),\n",
        "        NaiveDense(input_size=512, output_size=10, activation=ops.softmax),\n",
        "    ]\n",
        ")\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF3wrbTcQs3h"
      },
      "source": [
        "---\n",
        "####  **EJERCICIO**: Prueba a cambiar la funci贸n de activaci贸n de la capa oculta de las disponibles en [ops.nn](https://keras.io/api/ops/nn/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61KF13o7uIIm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_YvseeugWR"
      },
      "source": [
        "#### Generador de lotes o *batches*\n",
        "\n",
        "Esta clase nos permitir谩 iterar sobre las im谩genes de entrenamiento en *mini-batches*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVUExC7hugWR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PXxSP3SugWR"
      },
      "source": [
        "### Ejecutar un paso de entrenamiento\n",
        "\n",
        "La parte m谩s dif铆cil del proceso es el \"**paso de entrenamiento**\": actualizar los pesos del modelo despu茅s de procesar un lote de datos. Necesitamos:\n",
        "1. Calcular las predicciones del modelo para las im谩genes del lote.\n",
        "1. Calcular el valor de la p茅rdida para estas predicciones, dadas las etiquetas reales.\n",
        "1. Calcular el gradiente de la p茅rdida con respecto a los pesos del modelo.\n",
        "1. Mover los pesos una peque帽a cantidad en la direcci贸n opuesta al gradiente.\n",
        "\n",
        "El gradiente lo vamos a calcular con `GradientTape` de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdgGKjzD32Km"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.zeros(shape=())\n",
        "with tf.GradientTape() as tape:\n",
        "    y = 2 * x + 3\n",
        "grad_of_y_wrt_x = tape.gradient(y, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW-YoylIugWR"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # (1) llama a __call__()\n",
        "        predictions = model(images_batch)\n",
        "        # (2)\n",
        "        per_sample_losses = ops.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        # (2) media de elementos a trav茅s de las dimensiones del tensor\n",
        "        average_loss = ops.mean(per_sample_losses)\n",
        "    # (3) Calcula el gradiente del la funci贸n de coste/p茅rdida respecto a los pesos\n",
        "    # del modelo de todas las capas. Los gradientes de salida son una lista\n",
        "    # donde cada entrada corresponde con un peso de la lista model.weights\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    # (4) actualiza los pesos (a continuaci贸n)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gB5qSZ0VK-I"
      },
      "source": [
        "**La funci贸n `update_weights` mover谩 los pesos \"un poco\" en la direcci贸n que reduzca la p茅rdida para este lote**. La magnitud de este movimiento depender谩 del `learning_rate` y ser谩 en direcci贸n contaria al gradiente, por tanto basta con restar el gradiente multiplicado por `learning_rate` a los pesos para actualizarlos.\n",
        "\n",
        "**Nota Python**: [c贸mo funciona zip](https://www.freecodecamp.org/news/the-zip-function-in-python-explained-with-examples/).\n",
        "\n",
        "**Nota TF**: `assign_sub` equivale a `-=\n",
        "\n",
        "\n",
        "```\n",
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6V-aZ5AWtrx"
      },
      "source": [
        "En la pr谩ctica ser谩 muy raro que implementemos la actualizaci贸n de los pesos a mano y utilizaremos uno de los optimizadores de Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlEYGwT3ugWS"
      },
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEx1Hih-ugWS"
      },
      "source": [
        "### El bucle de aprendizaje completo\n",
        "\n",
        "Una 茅poca o *epoch* de aprendizaje consiste en repetir un paso de aprendizaje para cada lote del conjunto de entrenamiento. El bucle completo de aprendizaje es simplemente la repetici贸n de una 茅poca."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrL_f9piugWS"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ItBUzzUZ2gy"
      },
      "source": [
        "Probemos nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL2E5EEHugWS"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dQPbpK55jq2"
      },
      "source": [
        "---\n",
        "####  **EJERCICIO**: log p茅rdida\n",
        "\n",
        "Modifica el c贸digo anterior para guardar el hist贸rico de la funci贸n de p茅rdida y dibuja esta en una gr谩fica para poder estudiar la convergencia del algoritmo. Analiza la salida de la evoluci贸n de la funci贸n de error. 驴Ha sido siempre descendente?驴Qu茅 podr铆amos hacer para mejorar la precisi贸n?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naZlRe50zojW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1-JbszqzpRO"
      },
      "source": [
        "---\n",
        "####  **EJERCICIO**: Prueba a:\n",
        "* reemplazar el optimizador por [otro de Keras](https://keras.io/api/optimizers/).\n",
        "* Prueba a cambiar la tasa de aprendizaje y a activar el momento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrsTpKH8zvBv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knkPRk_-ugWT"
      },
      "source": [
        "### Evaluaci贸n del modelo\n",
        "\n",
        "Podemos evaluar el modelo eligiendo la neurona de salida con m谩ximo valor en la predicci贸n del conjunto de test y compar谩ndola con la etiqueta esperada\n",
        "\n",
        "####  **EJERCICIO**: Completa el c贸digo para elegir la neurona con mayor probabilidad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D65ho0WiugWT"
      },
      "outputs": [],
      "source": [
        "%%backend tensorflow\n",
        "predictions = model(test_images)\n",
        "predicted_labels = 1 # CAMBIAR AQU USANDO API DE KERAS\n",
        "matches = predicted_labels == test_labels\n",
        "f\"accuracy: {ops.mean(matches):.2f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "121qc_kH3QzT"
      },
      "source": [
        "####  **EJERCICIO**: todo junto\n",
        "\n",
        "Pon todo el c贸digo que hemos desarrollado en una 煤nica celda de manera que permita hacer varias ejecuciones.\n",
        "\n",
        "1. Definici贸n de clases (capa y modelo) y funciones auxiliares (batch)\n",
        "1. Optimizador y actualizaci贸n pesos\n",
        "1. Paso de entrenamiento y funci贸n fit()\n",
        "1. Cargar datos\n",
        "1. Definir modelo\n",
        "1. Ajustar el modelo llamando a fit()\n",
        "1. Evaluar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXAvlgM4T28L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "chapter02_network-from-scratch.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+eMIdjYtvtlsxFuKlEqr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}