{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter02_network-from-scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM/E1sCHwgWaN4IC50bCrFD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayrna/deep-learning-with-python-notebooks/blob/master/chapter02_network-from-scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S976n7dT52xs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Los bloques de construcción matemáticos del aprendizaje profundo (parte II)"
      ],
      "metadata": {
        "id": "leKwkJPWvPV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este cuaderno vamos a ver:\n",
        "\n",
        "* Un ejemplo de red neuronal\n",
        "* El concepto de tensor y operaciones con tensores\n",
        "* Cómo las redes neuronales aprenden a través del algoritmo de retropropagación y el descenso por gradiente\n",
        "\n",
        "**EJERCICIOS: Durante este cuaderno de prácticas verás ejercicios y preguntas marcadas con ❓❓❓. Puedes contestar añadiendo nuevos bloques de texto (breve) y/o código a continuación de la pregunta.**\n",
        "\n"
      ],
      "metadata": {
        "id": "VLKqo45Tu80M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este cuaderno está basado en los cuadernos del libro [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff).\n",
        "\n",
        "> This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "> **If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "> This notebook was generated for TensorFlow 2.6."
      ],
      "metadata": {
        "id": "1I35kAPLu7Z0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPUYr1xugWP"
      },
      "source": [
        "### Reimplementando nuestro ejemplo desde cero en TensorFlow\n",
        "\n",
        "Una forma de poner a prueba lo que se ha aprendido sobre algo es implementarlo \"desde cero\". Y esto vamos a hacer con una red neuronal. Obviamente no vamos a reimplementar operadores de matrices o algoritmos de optimización, pero si los componentes básicos de una red.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rad4u8KugWP"
      },
      "source": [
        "#### Clase Dense\n",
        "\n",
        "La clase `Dense` implementa la siguiente transformación de los datos de entrada donde `W` y `b` son los datos del modelo:\n",
        "\n",
        "```\n",
        "output = activation(dot(W, input) + b)\n",
        "```\n",
        "\n",
        "Donde la función de actividad suele ser `relu` para capas ocultas o `softmax` en la última capa.\n",
        "\n",
        "**Nota de orientación a objetos en Python**:\n",
        "* El método `__init__` es el constructor de la clase y se llama al crear una instancia de la clase para asignar valores por defecto a los atributos de la clase.\n",
        "* El método `__call__` es el método que se lanza cuando se llama a la instancia de la clase como si fuera una función.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGqA3sy3ugWP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class NaiveDense:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        self.activation = activation\n",
        "\n",
        "        w_shape = (input_size, output_size)\n",
        "        # Creamos una matriz inicializada aleatoriamente de forma (input_size, output_size)\n",
        "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
        "        self.W = tf.Variable(w_initial_value)\n",
        "\n",
        "        # Vector inicializado con ceros de forma (output_size,)\n",
        "        b_shape = (output_size,)\n",
        "        b_initial_value = tf.zeros(b_shape)\n",
        "        self.b = tf.Variable(b_initial_value)\n",
        "\n",
        "    def __call__(self, inputs): # forward pass\n",
        "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "        return [self.W, self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nota de orientación a objetos en Python**: `@property` se utiliza para definir un método `weights` que se comporta como un atributo/propiedad lo que significa que puede ser accedido como objeto sin la necesidad de llamarlo como un método (`objeto.weights()`). La función weights devuelve una lista que contiene los pesos (W) y los sesgos (b) de la capa. Esto permite que sean accesibles desde fuera de la clase pero al mismo tiempo que no se puedan modificar directamente fuera de la clase."
      ],
      "metadata": {
        "id": "IryasMQKuuhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❓❓❓ Intenta cambiar la forma de inicialización de los pesos y observa el efecto. ❓❓❓"
      ],
      "metadata": {
        "id": "hsE9tTRssFKp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX0Aiyr3ugWQ"
      },
      "source": [
        "#### Clase Sequential\n",
        "\n",
        "Esta clase se va a encargar de encadenar las capas. Va a empaquetar una lista de capas y expone un método `__call__()` que simplemente llama en orden a las capas subyacentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfso4YniugWQ"
      },
      "outputs": [],
      "source": [
        "class NaiveSequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.layers:\n",
        "           x = layer(x)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def weights(self):\n",
        "       weights = []\n",
        "       for layer in self.layers:\n",
        "           weights += layer.weights\n",
        "       return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando las clases `NaiveDense` y `NaiveSequential` podemos crear algo similar a un modelo de Keras:"
      ],
      "metadata": {
        "id": "j81P9OhoQetU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOIdPFPbugWQ"
      },
      "outputs": [],
      "source": [
        "model = NaiveSequential([\n",
        "    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
        "    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
        "])\n",
        "assert len(model.weights) == 4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "❓❓❓ **EJERCICIO**: Prueba a cambiar la función de activación de la capa oculta de las disponibles en [tf.nn](https://www.tensorflow.org/api_docs/python/tf/nn)❓❓❓"
      ],
      "metadata": {
        "id": "zF3wrbTcQs3h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61KF13o7uIIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_YvseeugWR"
      },
      "source": [
        "#### Generador de lotes o *batches*\n",
        "\n",
        "Esta clase nos permitirá iterar sobre las imágenes de entrenamiento en *mini-batches*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVUExC7hugWR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class BatchGenerator:\n",
        "    def __init__(self, images, labels, batch_size=128):\n",
        "        assert len(images) == len(labels)\n",
        "        self.index = 0\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.num_batches = math.ceil(len(images) / batch_size)\n",
        "\n",
        "    def next(self):\n",
        "        images = self.images[self.index : self.index + self.batch_size]\n",
        "        labels = self.labels[self.index : self.index + self.batch_size]\n",
        "        self.index += self.batch_size\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PXxSP3SugWR"
      },
      "source": [
        "### Ejecutar un paso de entrenamiento\n",
        "\n",
        "La parte más difícil del proceso es el \"**paso de entrenamiento**\": actualizar los pesos del modelo después de procesar un lote de datos. Necesitamos:\n",
        "1. Calcular las predicciones del modelo para las imágenes del lote.\n",
        "1. Calcular el valor de la pérdida para estas predicciones, dadas las etiquetas reales.\n",
        "1. Calcular el gradiente de la pérdida con respecto a los pesos del modelo.\n",
        "1. Mover los pesos una pequeña cantidad en la dirección opuesta al gradiente.\n",
        "\n",
        "El gradiente lo vamos a calcular con `GradientTape` de TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW-YoylIugWR"
      },
      "outputs": [],
      "source": [
        "def one_training_step(model, images_batch, labels_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # (1) llama a __call__()\n",
        "        predictions = model(images_batch)\n",
        "        # (2)\n",
        "        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "            labels_batch, predictions)\n",
        "        # (2) media de elementos a través de las dimensiones del tensor\n",
        "        average_loss = tf.reduce_mean(per_sample_losses)\n",
        "    # (3) Calcula el gradiente del la función de coste/pérdida respecto a los pesos\n",
        "    # del modelo de todas las capas. Los gradientes de salida son una lista\n",
        "    # donde cada entrada corresponde con un peso de la lista model.weights\n",
        "    gradients = tape.gradient(average_loss, model.weights)\n",
        "    # (4) actualiza los pesos (a continuación)\n",
        "    update_weights(gradients, model.weights)\n",
        "    return average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**La función `update_weights` moverá los pesos \"un poco\" en la dirección que reduzca la pérdida para este lote**. La magnitud de este movimiento dependerá del `learning_rate` y será en dirección contaria al gradiente, por tanto basta con restar el gradiente multiplicado por `learning_rate` a los pesos para actualizarlos.\n",
        "\n",
        "**Nota Python**: [cómo funciona zip](https://www.freecodecamp.org/news/the-zip-function-in-python-explained-with-examples/).\n",
        "\n",
        "**Nota TF**: `assign_sub` equivale a `-=\n",
        "\n",
        "\n",
        "```\n",
        "learning_rate = 1e-3\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    for g, w in zip(gradients, weights):\n",
        "        w.assign_sub(g * learning_rate)\n",
        "```"
      ],
      "metadata": {
        "id": "3gB5qSZ0VK-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la práctica será muy raro que implementemos la actualización de los pesos a mano y utilizaremos uno de los optimizadores de Keras:"
      ],
      "metadata": {
        "id": "H6V-aZ5AWtrx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlEYGwT3ugWS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "optimizer = optimizers.SGD(learning_rate=1e-3)\n",
        "\n",
        "def update_weights(gradients, weights):\n",
        "    optimizer.apply_gradients(zip(gradients, weights))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEx1Hih-ugWS"
      },
      "source": [
        "### El bucle de aprendizaje completo\n",
        "\n",
        "Una época o *epoch* de aprendizaje consiste en repetir un paso de aprendizaje para cada lote del conjunto de entrenamiento. El bucle completo de aprendizaje es simplemente la repetición de una época."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrL_f9piugWS"
      },
      "outputs": [],
      "source": [
        "def fit(model, images, labels, epochs, batch_size=128):\n",
        "    for epoch_counter in range(epochs):\n",
        "        print(f\"Epoch {epoch_counter}\")\n",
        "        batch_generator = BatchGenerator(images, labels)\n",
        "        for batch_counter in range(batch_generator.num_batches):\n",
        "            images_batch, labels_batch = batch_generator.next()\n",
        "            loss = one_training_step(model, images_batch, labels_batch)\n",
        "            if batch_counter % 100 == 0:\n",
        "                print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probemos nuestro modelo:"
      ],
      "metadata": {
        "id": "7ItBUzzUZ2gy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL2E5EEHugWS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "\n",
        "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "❓❓❓\n",
        "\n",
        "**EJERCICIO**: Modifica el código anterior para guardar el histórico de la función de pérdida y dibuja esta en una gráfica para poder estudiar la convergencia del algoritmo. Analiza la salida de la evolución de la función de error. ¿Ha sido siempre descendente?¿Qué podríamos hacer para mejorar la precisión?\n",
        "\n",
        "❓❓❓"
      ],
      "metadata": {
        "id": "7dQPbpK55jq2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "naZlRe50zojW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "❓❓❓\n",
        "\n",
        "**EJERCICIO**: Prueba:\n",
        "* reemplazar el optimizador por [otro de Keras](https://keras.io/api/optimizers/).\n",
        "* Prueba a cambiar la tasa de aprendizaje y a activar el momento.\n",
        "\n",
        "❓❓❓"
      ],
      "metadata": {
        "id": "q1-JbszqzpRO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrsTpKH8zvBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knkPRk_-ugWT"
      },
      "source": [
        "### Evaluación del modelo\n",
        "\n",
        "Podemos evaluar el modelo eligiendo la neurona de salida con máximo valor en la predicción del conjunto de test y comparándola con la etiqueta esperada\n",
        "\n",
        "❓❓❓ **EJERCICIO**: Completa el código para elegir la neurona con mayor probabilidad\n",
        "❓❓❓\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D65ho0WiugWT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "predictions = model(test_images)\n",
        "predictions = predictions.numpy()\n",
        "predicted_labels = 1 # CAMBIAR AQUÍ\n",
        "matches = predicted_labels == test_labels\n",
        "print(f\"accuracy: {matches.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "❓❓❓\n",
        "\n",
        "**EJERCICIO**:\n",
        "\n",
        "Pon todo el código que hemos desarrollado en una única celda de manera que permita hacer varias ejecuciones.\n",
        "\n",
        "1. Definición de clases (capa y modelo) y funciones auxiliares (batch)\n",
        "1. Optimizador y actualización pesos\n",
        "1. Paso de entrenamiento y función fit()\n",
        "1. Cargar datos\n",
        "1. Definir modelo\n",
        "1. Ajustar el modelo llamando a fit()\n",
        "1. Evaluar el modelo\n",
        "\n",
        "❓❓❓"
      ],
      "metadata": {
        "id": "121qc_kH3QzT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dXAvlgM4T28L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}